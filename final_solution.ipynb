{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['target', 'ID_code']\n",
    "extra_features = []\n",
    "for column in df.drop(['target', 'ID_code'], axis=1):\n",
    "    to_drop.append(column)\n",
    "    for col in df.drop(to_drop, axis=1):\n",
    "        corr = df['target'].corr(df[[column, col]].mean(axis=1))\n",
    "        if  corr >= 0.08 or corr <= -0.08:\n",
    "            extra_features.append([column, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['target', 'ID_code']\n",
    "extra_features_norm = []\n",
    "for column in df.drop(['target', 'ID_code'], axis=1):\n",
    "    to_drop.append(column)\n",
    "    for col in df.drop(to_drop, axis=1):\n",
    "        corr = df['target'].corr(np.sqrt(df[column]**2+df[col]**2))\n",
    "        if  corr >= 0.08 or corr <= -0.08:\n",
    "            extra_features_norm.append([column, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['target', 'ID_code']\n",
    "extra_features_scale = []\n",
    "for column in df.drop(['target', 'ID_code'], axis=1):\n",
    "    corr = df['target'].corr(np.round(df[column]*100))\n",
    "    if  corr >= 0.05 or corr <= -0.05:\n",
    "        extra_features_scale.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['target', 'ID_code']\n",
    "extra_features_binning = []\n",
    "for column in df.drop(['target', 'ID_code'], axis=1):\n",
    "    corr = df['target'].corr(pd.qcut(\n",
    "        df[column],\n",
    "        [0, 0.25, 0.5, 0.75, 1], labels=False))\n",
    "    if  corr >= 0.05 or corr <= -0.05:\n",
    "        extra_features_binning.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in extra_features:\n",
    "    df_copy['{}_{}_mean'.format(x,y)] = df[[x, y]].mean(axis=1)\n",
    "\n",
    "for x, y in extra_features_norm:\n",
    "    df_copy['{}_{}_norm'.format(x,y)] = np.sqrt(df[x]**2+df[y]**2)\n",
    "\n",
    "# for x in extra_features_scale:\n",
    "#     df_copy['{}_scale'.format(x)] = np.round(df[column]*100)\n",
    "\n",
    "# for x in extra_features_binning:\n",
    "#     df_copy['{}_binning'.format(x)] = pd.qcut(df[column], [0, 0.25, 0.5, 0.75, 1], labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2129)\n",
    "for train_id, valid_id in split.split(df_copy, df_copy['target']):\n",
    "    df_train = df_copy.loc[train_id]\n",
    "    df_valid = df_copy.loc[valid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['ID_code', 'target'], axis=1)\n",
    "y_train = df_train['target']\n",
    "\n",
    "X_valid = df_valid.drop(['ID_code', 'target'], axis=1)\n",
    "y_valid = df_valid['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = df_train.drop(['ID_code', 'target'], axis=1)\n",
    "y_tr = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop(['ID_code', 'target'], axis=1)\n",
    "y = df_copy['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ensemble of different resampled datasets\n",
    "\n",
    "Used ensemble of different resampled datasets to deal with unbalanced data(negative class has N times more samples than positive class). All negative samples in train dataset splitted into N chunks of equal length. Then create N datasets in which each dataset contains all positive samples and one of the chunks with negative samples. Build N models on N created datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n"
     ]
    }
   ],
   "source": [
    "negatives = np.array_split(df_copy[df_copy['target']==0], 9)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "models = []\n",
    "scalers = []\n",
    "\n",
    "for i, negative in enumerate(negatives):\n",
    "    print(f'Iteration {i+1}')\n",
    "    train = pd.concat([df_copy[df_copy['target']==1], negative], axis=0).sample(frac=1)\n",
    "\n",
    "    X_train = train.drop(['ID_code', 'target'], axis=1)\n",
    "    y_train = train['target']\n",
    "        \n",
    "    catboost = CatBoostClassifier(n_estimators=10000,\n",
    "                                  max_depth=3,\n",
    "                                  learning_rate=0.025,\n",
    "                                  reg_lambda=25,\n",
    "                                  logging_level='Silent',\n",
    "                                  random_seed=63)\n",
    "\n",
    "    catboost.fit(X_train, y_train)\n",
    "    \n",
    "    models.append(catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "ROC AUC train:  0.9503300872223455\n",
      "ROC AUC valid:  0.8955294331566181\n",
      "Iteration 2\n",
      "ROC AUC train:  0.9528647544464397\n",
      "ROC AUC valid:  0.8953415800375555\n",
      "Iteration 3\n",
      "ROC AUC train:  0.950256435570037\n",
      "ROC AUC valid:  0.8949398090149586\n",
      "Iteration 4\n",
      "ROC AUC train:  0.9486606721498952\n",
      "ROC AUC valid:  0.8946182718978759\n",
      "Iteration 5\n",
      "ROC AUC train:  0.9501715329749129\n",
      "ROC AUC valid:  0.8938265730823372\n",
      "Iteration 6\n",
      "ROC AUC train:  0.951310751553658\n",
      "ROC AUC valid:  0.8949874792242236\n",
      "Iteration 7\n",
      "ROC AUC train:  0.9514719912881622\n",
      "ROC AUC valid:  0.8951656116305632\n",
      "Iteration 8\n",
      "ROC AUC train:  0.9501351838082842\n",
      "ROC AUC valid:  0.8949261543864888\n",
      "Iteration 9\n",
      "ROC AUC train:  0.9505784655903085\n",
      "ROC AUC valid:  0.8942136385886024\n",
      "Iteration 10\n",
      "ROC AUC train:  0.9510293793576216\n",
      "ROC AUC valid:  0.8956837477426652\n"
     ]
    }
   ],
   "source": [
    "negatives = np.array_split(df_train[df_train['target']==0], 10)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "models = []\n",
    "\n",
    "for i, negative in enumerate(negatives):\n",
    "    print(f'Iteration {i+1}')\n",
    "    train = pd.concat([df_train[df_train['target']==1], negative], axis=0).sample(frac=1)\n",
    "\n",
    "    X_train = train.drop(['ID_code', 'target'], axis=1)\n",
    "    y_train = train['target']\n",
    "    catboost = CatBoostClassifier(n_estimators=10000,\n",
    "                                  max_depth=3,\n",
    "                                  learning_rate=0.025,\n",
    "                                  reg_lambda=25,\n",
    "                                  logging_level='Silent',\n",
    "                                  random_seed=63)\n",
    "\n",
    "    catboost.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred_train = catboost.predict_proba(X_train)[:,1]\n",
    "    y_pred_valid = catboost.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    models.append(catboost)\n",
    "    predictions.append(y_pred_valid)\n",
    "\n",
    "    print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "    print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC valid:  0.8982718633071441\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC valid: ', roc_auc_score(y_valid, np.mean(predictions, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC valid:  0.8987975215639423\n"
     ]
    }
   ],
   "source": [
    "# 5000, learning_rate=0.05\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, np.mean(predictions, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC valid:  0.8990693350921878\n"
     ]
    }
   ],
   "source": [
    "# 10000, learning_rate=0.025\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, np.mean(predictions, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC valid:  0.8991240089159537\n"
     ]
    }
   ],
   "source": [
    "# 10000, learning_rate=0.025\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, np.mean(\n",
    "    [\n",
    "        catboost_valid_pred[0],\n",
    "        catboost_valid_pred[1],\n",
    "        catboost_valid_pred[2],\n",
    "        catboost_valid_pred[3],\n",
    "\n",
    "        catboost_valid_pred[5],\n",
    "        catboost_valid_pred[6],\n",
    "        catboost_valid_pred[7],\n",
    "\n",
    "        catboost_valid_pred[9]\n",
    "    ], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_valid_pred = deepcopy(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_models = deepcopy(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "ROC AUC train:  0.9255883050224645\n",
      "ROC AUC valid:  0.8955294331566181\n",
      "Iteration 2\n",
      "ROC AUC train:  0.9528647544464397\n",
      "ROC AUC valid:  0.8953415800375555\n",
      "Iteration 3\n",
      "ROC AUC train:  0.9252235594995553\n",
      "ROC AUC valid:  0.8949398090149586\n",
      "Iteration 4\n",
      "ROC AUC train:  0.9248981725793834\n",
      "ROC AUC valid:  0.8946182718978759\n",
      "Iteration 5\n",
      "ROC AUC train:  0.9257100193839822\n",
      "ROC AUC valid:  0.8938265730823372\n",
      "Iteration 6\n",
      "ROC AUC train:  0.9261229390069481\n",
      "ROC AUC valid:  0.8949874792242236\n",
      "Iteration 7\n",
      "ROC AUC train:  0.925262122979005\n",
      "ROC AUC valid:  0.8951656116305632\n",
      "Iteration 8\n",
      "ROC AUC train:  0.925450420273217\n",
      "ROC AUC valid:  0.8949261543864888\n",
      "Iteration 9\n",
      "ROC AUC train:  0.9251532126952114\n",
      "ROC AUC valid:  0.8942136385886024\n",
      "Iteration 10\n",
      "ROC AUC train:  0.9255984298804152\n",
      "ROC AUC valid:  0.8956837477426652\n"
     ]
    }
   ],
   "source": [
    "negatives = np.array_split(df_train[df_train['target']==0], 10)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "\n",
    "for i, model in enumerate(catboost_models):\n",
    "    print(f'Iteration {i+1}')\n",
    "    train = pd.concat([df_train[df_train['target']==1], negative], axis=0).sample(frac=1)\n",
    "\n",
    "    X_train = train.drop(['ID_code', 'target'], axis=1)\n",
    "    y_train = train['target']\n",
    "\n",
    "    y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    \n",
    "    predictions.append(y_pred_valid)\n",
    "\n",
    "    print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "    print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = [model.predict_proba(X_test)[:,1] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.51353943, 0.54810137, 0.76105474, ..., 0.03965492, 0.52458607,\n",
       "        0.3681197 ]),\n",
       " array([0.45200251, 0.58584933, 0.72726154, ..., 0.03136979, 0.37520929,\n",
       "        0.39195908]),\n",
       " array([0.48648874, 0.56760553, 0.71321079, ..., 0.04521828, 0.3873024 ,\n",
       "        0.34407176]),\n",
       " array([0.49046804, 0.59266761, 0.75203243, ..., 0.04171874, 0.39158973,\n",
       "        0.34588926]),\n",
       " array([0.48559157, 0.69964847, 0.67615222, ..., 0.03398007, 0.43168128,\n",
       "        0.29355007]),\n",
       " array([0.51502859, 0.6364025 , 0.73461508, ..., 0.02221924, 0.27103338,\n",
       "        0.27638584]),\n",
       " array([0.50268163, 0.70179678, 0.65646144, ..., 0.03283017, 0.43848574,\n",
       "        0.45370141]),\n",
       " array([0.63235574, 0.77388221, 0.69470053, ..., 0.03546403, 0.39659013,\n",
       "        0.22485201]),\n",
       " array([0.61901025, 0.59334106, 0.76609618, ..., 0.02192895, 0.3763465 ,\n",
       "        0.42818916])]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([\n",
    "    y_pred_test[0],\n",
    "    y_pred_test[1],\n",
    "    y_pred_test[2],\n",
    "    y_pred_test[3],\n",
    "\n",
    "    y_pred_test[5],\n",
    "    y_pred_test[6],\n",
    "    y_pred_test[7],\n",
    "\n",
    "    y_pred_test[9]\n",
    "], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(y_pred, filename):\n",
    "    subm = np.column_stack([df_test['ID_code'], y_pred])\n",
    "    with open(filename, 'w+') as f:\n",
    "        f.write('ID_code,target\\n')\n",
    "        for row in subm:\n",
    "            f.write('{},{}\\n'.format(row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(np.mean(y_pred_test, axis=0), './submissions/catboost_ensemble_sampling_all_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3500 rounds.\n",
      "[1000]\tvalid_0's auc: 0.855104\n",
      "[2000]\tvalid_0's auc: 0.875306\n",
      "[3000]\tvalid_0's auc: 0.8839\n",
      "[4000]\tvalid_0's auc: 0.888864\n",
      "[5000]\tvalid_0's auc: 0.891466\n",
      "[6000]\tvalid_0's auc: 0.892394\n",
      "[7000]\tvalid_0's auc: 0.892881\n",
      "[8000]\tvalid_0's auc: 0.893115\n",
      "[9000]\tvalid_0's auc: 0.893244\n",
      "[10000]\tvalid_0's auc: 0.89331\n",
      "[11000]\tvalid_0's auc: 0.893302\n",
      "[12000]\tvalid_0's auc: 0.893312\n",
      "[13000]\tvalid_0's auc: 0.893306\n",
      "[14000]\tvalid_0's auc: 0.893216\n",
      "[15000]\tvalid_0's auc: 0.893159\n"
     ]
    }
   ],
   "source": [
    "param = {'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1}\n",
    "\n",
    "\n",
    "cv_split = StratifiedKFold(n_splits=5, random_state=2129)\n",
    "\n",
    "y_pred_valid_lightgbm = 0*y\n",
    "\n",
    "lgb_models = []\n",
    "\n",
    "for train_id, valid_id in cv_split.split(X,y):\n",
    "    X_train, X_valid = X.iloc[train_id], X.iloc[valid_id]\n",
    "    y_train, y_valid = y.iloc[train_id], y.iloc[valid_id]\n",
    "        \n",
    "    data_train = lgb.Dataset(X_train, label=y_train)\n",
    "    data_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                    data_train,\n",
    "                    1000000,\n",
    "                    valid_sets=[data_valid],\n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds=3500)\n",
    "    \n",
    "    lgb_models.append(model)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    \n",
    "    y_pred_valid_lightgbm.iloc[valid_id] = y_pred_valid\n",
    "\n",
    "    print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "    print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5000 rounds.\n",
      "[100]\tvalid_0's auc: 0.756398\n",
      "[200]\tvalid_0's auc: 0.79136\n",
      "[300]\tvalid_0's auc: 0.809593\n",
      "[400]\tvalid_0's auc: 0.821838\n",
      "[500]\tvalid_0's auc: 0.831376\n",
      "[600]\tvalid_0's auc: 0.838722\n",
      "[700]\tvalid_0's auc: 0.844718\n",
      "[800]\tvalid_0's auc: 0.850024\n",
      "[900]\tvalid_0's auc: 0.854257\n",
      "[1000]\tvalid_0's auc: 0.858013\n",
      "[1100]\tvalid_0's auc: 0.861273\n",
      "[1200]\tvalid_0's auc: 0.864301\n",
      "[1300]\tvalid_0's auc: 0.866846\n",
      "[1400]\tvalid_0's auc: 0.869118\n",
      "[1500]\tvalid_0's auc: 0.871131\n",
      "[1600]\tvalid_0's auc: 0.873031\n",
      "[1700]\tvalid_0's auc: 0.874626\n",
      "[1800]\tvalid_0's auc: 0.876188\n",
      "[1900]\tvalid_0's auc: 0.877428\n",
      "[2000]\tvalid_0's auc: 0.878591\n",
      "[2100]\tvalid_0's auc: 0.879738\n",
      "[2200]\tvalid_0's auc: 0.880765\n",
      "[2300]\tvalid_0's auc: 0.881741\n",
      "[2400]\tvalid_0's auc: 0.882605\n",
      "[2500]\tvalid_0's auc: 0.883424\n",
      "[2600]\tvalid_0's auc: 0.884203\n",
      "[2700]\tvalid_0's auc: 0.884926\n",
      "[2800]\tvalid_0's auc: 0.885642\n",
      "[2900]\tvalid_0's auc: 0.886305\n",
      "[3000]\tvalid_0's auc: 0.886877\n",
      "[3100]\tvalid_0's auc: 0.887473\n",
      "[3200]\tvalid_0's auc: 0.887968\n",
      "[3300]\tvalid_0's auc: 0.888473\n",
      "[3400]\tvalid_0's auc: 0.888957\n",
      "[3500]\tvalid_0's auc: 0.889394\n",
      "[3600]\tvalid_0's auc: 0.88977\n",
      "[3700]\tvalid_0's auc: 0.890177\n",
      "[3800]\tvalid_0's auc: 0.890543\n",
      "[3900]\tvalid_0's auc: 0.890878\n",
      "[4000]\tvalid_0's auc: 0.891209\n",
      "[4100]\tvalid_0's auc: 0.891496\n",
      "[4200]\tvalid_0's auc: 0.891783\n",
      "[4300]\tvalid_0's auc: 0.892053\n",
      "[4400]\tvalid_0's auc: 0.892278\n",
      "[4500]\tvalid_0's auc: 0.892511\n",
      "[4600]\tvalid_0's auc: 0.89273\n",
      "[4700]\tvalid_0's auc: 0.892924\n",
      "[4800]\tvalid_0's auc: 0.893097\n",
      "[4900]\tvalid_0's auc: 0.893275\n",
      "[5000]\tvalid_0's auc: 0.893487\n",
      "[5100]\tvalid_0's auc: 0.893621\n",
      "[5200]\tvalid_0's auc: 0.89372\n",
      "[5300]\tvalid_0's auc: 0.893876\n",
      "[5400]\tvalid_0's auc: 0.893978\n",
      "[5500]\tvalid_0's auc: 0.89411\n",
      "[5600]\tvalid_0's auc: 0.894203\n",
      "[5700]\tvalid_0's auc: 0.894306\n",
      "[5800]\tvalid_0's auc: 0.894375\n",
      "[5900]\tvalid_0's auc: 0.894469\n",
      "[6000]\tvalid_0's auc: 0.894558\n",
      "[6100]\tvalid_0's auc: 0.89462\n",
      "[6200]\tvalid_0's auc: 0.894699\n",
      "[6300]\tvalid_0's auc: 0.894753\n",
      "[6400]\tvalid_0's auc: 0.894781\n",
      "[6500]\tvalid_0's auc: 0.894835\n",
      "[6600]\tvalid_0's auc: 0.894869\n",
      "[6700]\tvalid_0's auc: 0.894904\n",
      "[6800]\tvalid_0's auc: 0.894912\n",
      "[6900]\tvalid_0's auc: 0.894918\n",
      "[7000]\tvalid_0's auc: 0.894978\n",
      "[7100]\tvalid_0's auc: 0.894993\n",
      "[7200]\tvalid_0's auc: 0.895029\n",
      "[7300]\tvalid_0's auc: 0.895062\n",
      "[7400]\tvalid_0's auc: 0.895083\n",
      "[7500]\tvalid_0's auc: 0.895073\n",
      "[7600]\tvalid_0's auc: 0.895098\n",
      "[7700]\tvalid_0's auc: 0.895114\n",
      "[7800]\tvalid_0's auc: 0.895165\n",
      "[7900]\tvalid_0's auc: 0.895162\n",
      "[8000]\tvalid_0's auc: 0.895168\n",
      "[8100]\tvalid_0's auc: 0.895153\n",
      "[8200]\tvalid_0's auc: 0.895166\n",
      "[8300]\tvalid_0's auc: 0.89517\n",
      "[8400]\tvalid_0's auc: 0.895198\n",
      "[8500]\tvalid_0's auc: 0.895227\n",
      "[8600]\tvalid_0's auc: 0.895237\n",
      "[8700]\tvalid_0's auc: 0.895268\n",
      "[8800]\tvalid_0's auc: 0.895274\n",
      "[8900]\tvalid_0's auc: 0.895294\n",
      "[9000]\tvalid_0's auc: 0.895318\n",
      "[9100]\tvalid_0's auc: 0.89533\n",
      "[9200]\tvalid_0's auc: 0.895298\n",
      "[9300]\tvalid_0's auc: 0.895311\n",
      "[9400]\tvalid_0's auc: 0.895318\n",
      "[9500]\tvalid_0's auc: 0.895321\n",
      "[9600]\tvalid_0's auc: 0.895317\n",
      "[9700]\tvalid_0's auc: 0.895298\n",
      "[9800]\tvalid_0's auc: 0.895289\n",
      "[9900]\tvalid_0's auc: 0.895256\n",
      "[10000]\tvalid_0's auc: 0.895276\n",
      "[10100]\tvalid_0's auc: 0.895282\n",
      "[10200]\tvalid_0's auc: 0.89527\n",
      "[10300]\tvalid_0's auc: 0.895249\n",
      "[10400]\tvalid_0's auc: 0.895252\n",
      "[10500]\tvalid_0's auc: 0.895265\n",
      "[10600]\tvalid_0's auc: 0.895259\n",
      "[10700]\tvalid_0's auc: 0.895228\n",
      "[10800]\tvalid_0's auc: 0.895225\n",
      "[10900]\tvalid_0's auc: 0.895222\n",
      "[11000]\tvalid_0's auc: 0.895201\n",
      "[11100]\tvalid_0's auc: 0.895185\n",
      "[11200]\tvalid_0's auc: 0.895151\n",
      "[11300]\tvalid_0's auc: 0.895161\n",
      "[11400]\tvalid_0's auc: 0.895152\n",
      "[11500]\tvalid_0's auc: 0.89511\n",
      "[11600]\tvalid_0's auc: 0.895108\n",
      "[11700]\tvalid_0's auc: 0.895084\n",
      "[11800]\tvalid_0's auc: 0.895086\n",
      "[11900]\tvalid_0's auc: 0.895069\n",
      "[12000]\tvalid_0's auc: 0.895063\n",
      "[12100]\tvalid_0's auc: 0.895036\n",
      "[12200]\tvalid_0's auc: 0.895015\n",
      "[12300]\tvalid_0's auc: 0.895021\n",
      "[12400]\tvalid_0's auc: 0.894997\n",
      "[12500]\tvalid_0's auc: 0.894973\n",
      "[12600]\tvalid_0's auc: 0.894982\n",
      "[12700]\tvalid_0's auc: 0.894975\n",
      "[12800]\tvalid_0's auc: 0.894949\n",
      "[12900]\tvalid_0's auc: 0.894954\n",
      "[13000]\tvalid_0's auc: 0.894928\n",
      "[13100]\tvalid_0's auc: 0.894919\n",
      "[13200]\tvalid_0's auc: 0.894919\n",
      "[13300]\tvalid_0's auc: 0.894903\n",
      "[13400]\tvalid_0's auc: 0.89488\n",
      "[13500]\tvalid_0's auc: 0.894879\n",
      "[13600]\tvalid_0's auc: 0.894873\n",
      "[13700]\tvalid_0's auc: 0.894857\n",
      "[13800]\tvalid_0's auc: 0.894834\n",
      "[13900]\tvalid_0's auc: 0.894828\n",
      "[14000]\tvalid_0's auc: 0.894827\n",
      "Early stopping, best iteration is:\n",
      "[9097]\tvalid_0's auc: 0.895335\n"
     ]
    }
   ],
   "source": [
    "data_train = lgb.Dataset(X_train, label=y_train)\n",
    "data_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1,\n",
    "    'random_state': 2129,\n",
    "}\n",
    "\n",
    "clf = lgb.train(params,\n",
    "                data_train,\n",
    "                20000,\n",
    "                valid_sets=[data_valid],\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train:  0.9742343115775871\n",
      "ROC AUC valid:  0.8953884759083959\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_valid = clf.predict(X_valid)\n",
    "print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train:  0.946276533090301\n",
      "ROC AUC valid:  0.8902662410570826\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = catboost.predict_proba(X_train)[:,1]\n",
    "y_pred_valid = catboost.predict_proba(X_valid)[:,1]\n",
    "print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train:  0.9207569001708658\n",
      "ROC AUC valid:  0.8937263653937096\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = catboost.predict_proba(X_train)[:,1]\n",
    "y_pred_valid = catboost.predict_proba(X_valid)[:,1]\n",
    "print('ROC AUC train: ', roc_auc_score(y_train, y_pred_train))\n",
    "print('ROC AUC valid: ', roc_auc_score(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
